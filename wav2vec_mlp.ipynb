{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNL2btYRQ0ulR2MdZCHQeBe"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"slEqAg0Qjt2L","executionInfo":{"status":"ok","timestamp":1740142776173,"user_tz":-60,"elapsed":26382,"user":{"displayName":"Yijie Xu","userId":"05131023991450583544"}},"outputId":"a5a864d2-ff9f-4634-d18b-463366657eec"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["# Get categories and extract files\n"],"metadata":{"id":"SFPXPGuJpFKe"}},{"cell_type":"code","source":["import tarfile\n","\n","tar_file = \"/content/drive/MyDrive/speech_commands_v0.02.tar.gz\"\n","extract_path = \"/content/speech_commands_v0.02\"\n","\n","with tarfile.open(tar_file, \"r:gz\") as tar:\n","    tar.extractall(extract_path)\n","\n","print(\"file extracted \")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"OHBlltBsmJ-A","executionInfo":{"status":"ok","timestamp":1740146264121,"user_tz":-60,"elapsed":80502,"user":{"displayName":"Yijie Xu","userId":"05131023991450583544"}},"outputId":"56bc8f5a-1f9a-42d6-cfd1-58bdfe84b577"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["file extracted \n"]}]},{"cell_type":"code","source":["import torch\n","\n","# Check if GPU is available, otherwise use CPU\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(f\"Using device: {device}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FUDAFRreqiRW","executionInfo":{"status":"ok","timestamp":1740146283675,"user_tz":-60,"elapsed":2815,"user":{"displayName":"Yijie Xu","userId":"05131023991450583544"}},"outputId":"5e410af8-f243-44c6-be5e-7268317c9b7d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n"]}]},{"cell_type":"code","source":["import os\n","from sklearn.model_selection import train_test_split\n","\n","DATASET_PATH = \"/content/speech_commands_v0.02\"\n","CATEGORIES = [\"yes\", \"no\", \"up\", \"down\", \"left\", \"right\", \"on\", \"off\", \"stop\", \"go\"]  # 10 target cat\n","\n","X_paths = []\n","Y_labels = []\n","\n","for label in CATEGORIES:\n","    label_path = os.path.join(DATASET_PATH, label)\n","    if os.path.isdir(label_path):\n","        for file_name in os.listdir(label_path):\n","            if file_name.endswith(\".wav\"):\n","                X_paths.append(os.path.join(label_path, file_name))\n","                Y_labels.append(CATEGORIES.index(label))\n","\n","print(f\"Total found {len(X_paths)} audio files\")\n","\n","# Split dataset: 80% train, 20% test\n","X_train_paths, X_test_paths, Y_train, Y_test = train_test_split(\n","    X_paths, Y_labels, test_size=0.2, random_state=2, stratify=Y_labels\n",")\n","\n","print(f\"Training set: {len(X_train_paths)} samples\")\n","print(f\"Testing set: {len(X_test_paths)} samples\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9nwZ0bUCoG3X","executionInfo":{"status":"ok","timestamp":1740146888805,"user_tz":-60,"elapsed":2380,"user":{"displayName":"Yijie Xu","userId":"05131023991450583544"}},"outputId":"71391fae-b63a-447a-d171-160b77bea050"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Total found 38546 audio files\n","Training set: 30836 samples\n","Testing set: 7710 samples\n"]}]},{"cell_type":"markdown","source":["# Get Wav2Vec2.0 features"],"metadata":{"id":"3bJUoqjio83L"}},{"cell_type":"code","source":["import librosa\n","import numpy as np\n","import torch #deeplearning\n","from transformers import Wav2Vec2Processor, Wav2Vec2Model #huggingface\n","\n","# Wav2Vec2.0  model\n","processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base-960h\")\n","model = Wav2Vec2Model.from_pretrained(\"facebook/wav2vec2-base-960h\").to(device)  # Move to GPU\n","\n","#extract Wav2Vec2.0 features to a single audio file\n","def extract_wav2vec_features(audio_path):\n","    y, sr = librosa.load(audio_path, sr=16000)  # Load the audio file\n","    input_values = processor(y, return_tensors=\"pt\", sampling_rate=16000).input_values.to(device)  # Convert to model input format & to GPU\n","\n","    with torch.no_grad():\n","        outputs = model(input_values)  # Run model & extract features\n","\n","    return outputs.last_hidden_state.mean(dim=1).cpu().numpy()  # Apply mean pooling & to NumPy array\n","\n","# Batch processing (speed up extraction)\n","def batch_extract_wav2vec_features(audio_paths, batch_size=8):\n","    features = []\n","\n","    for i in range(0, len(audio_paths), batch_size):\n","        batch_paths = audio_paths[i:i+batch_size]\n","        batch_audio = [librosa.load(path, sr=16000)[0] for path in batch_paths]  # Load multiple audio files\n","\n","        # Convert batch to model input format and move to GPU\n","        input_values = processor(batch_audio, return_tensors=\"pt\", padding=True, sampling_rate=16000).input_values.to(device)\n","\n","        with torch.no_grad():\n","            outputs = model(input_values)  # Run Wav2Vec2.0 model on the batch\n","\n","        # Apply mean pooling and convert to NumPy array\n","        batch_features = outputs.last_hidden_state.mean(dim=1).cpu().numpy()\n","        features.extend(batch_features)\n","\n","\n","        # Print log only every 5000 samples\n","        if i % 5000 == 0 or i + batch_size >= len(audio_paths):\n","            print(f\"Processed {i+len(batch_paths)}/{len(audio_paths)} samples...\")\n","\n","        #print(f\"Processed {i+len(batch_paths)}/{len(audio_paths)} samples...\")\n","\n","    return np.array(features)\n","\n","# Start feature extraction\n","print(\"Extracting Wav2Vec2.0 features\")\n","X_train_wav2vec = batch_extract_wav2vec_features(X_train_paths, batch_size=8)\n","\n","print(f\"Extraction complete! Training dataset shape: {X_train_wav2vec.shape}\")\n","\n","print(f\"------------------------------------------------------------------\")\n","X_test_wav2vec = batch_extract_wav2vec_features(X_test_paths, batch_size=8)\n","\n","print(f\"Extraction complete! Test dataset shape: {X_test_wav2vec.shape}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q-KM93LEpBs8","executionInfo":{"status":"ok","timestamp":1740148241888,"user_tz":-60,"elapsed":191316,"user":{"displayName":"Yijie Xu","userId":"05131023991450583544"}},"outputId":"4d029c25-a9c8-4fff-d92d-c4562df11e50"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Extracting Wav2Vec2.0 features\n","Processed 8/30836 samples...\n","Processed 5008/30836 samples...\n","Processed 10008/30836 samples...\n","Processed 15008/30836 samples...\n","Processed 20008/30836 samples...\n","Processed 25008/30836 samples...\n","Processed 30008/30836 samples...\n","Processed 30836/30836 samples...\n","Extraction complete! Training dataset shape: (30836, 768)\n","------------------------------------------------------------------\n","Processed 8/7710 samples...\n","Processed 5008/7710 samples...\n","Processed 7710/7710 samples...\n","Extraction complete! Test dataset shape: (7710, 768)\n"]}]},{"cell_type":"markdown","source":["# Training MLP Classifer"],"metadata":{"id":"zjaUnoN6tMMS"}},{"cell_type":"code","source":["from sklearn.neural_network import MLPClassifier\n","from sklearn.metrics import accuracy_score\n","\n","# Train MLP classifier\n","clf = MLPClassifier(hidden_layer_sizes=(128, 64), activation='relu', max_iter=200, solver='adam', batch_size=512, verbose = True, alpha = 0.005)#l2 regularization\n","clf.fit(X_train_wav2vec, Y_train)\n","\n","# Evaluation\n","Y_pred = clf.predict(X_test_wav2vec)\n","accuracy = accuracy_score(Y_test, Y_pred)\n","\n","print(f\"Wav2Vec2.0 + MLP Test Accuracy: {accuracy:.4f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E69X-SYVpv7a","executionInfo":{"status":"ok","timestamp":1740150012747,"user_tz":-60,"elapsed":1149651,"user":{"displayName":"Yijie Xu","userId":"05131023991450583544"}},"outputId":"600cc62d-8b56-484a-fb06-c60484a609c4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Iteration 1, loss = 1.31000024\n","Iteration 2, loss = 0.40335484\n","Iteration 3, loss = 0.31281104\n","Iteration 4, loss = 0.27912516\n","Iteration 5, loss = 0.26058057\n","Iteration 6, loss = 0.24713123\n","Iteration 7, loss = 0.23480921\n","Iteration 8, loss = 0.22682017\n","Iteration 9, loss = 0.21983283\n","Iteration 10, loss = 0.21255816\n","Iteration 11, loss = 0.20929381\n","Iteration 12, loss = 0.20154567\n","Iteration 13, loss = 0.19864978\n","Iteration 14, loss = 0.19388141\n","Iteration 15, loss = 0.19203957\n","Iteration 16, loss = 0.18872586\n","Iteration 17, loss = 0.18418554\n","Iteration 18, loss = 0.17986955\n","Iteration 19, loss = 0.17954967\n","Iteration 20, loss = 0.17653211\n","Iteration 21, loss = 0.17561824\n","Iteration 22, loss = 0.17320583\n","Iteration 23, loss = 0.17638767\n","Iteration 24, loss = 0.16687313\n","Iteration 25, loss = 0.16709057\n","Iteration 26, loss = 0.16389270\n","Iteration 27, loss = 0.16135906\n","Iteration 28, loss = 0.16228216\n","Iteration 29, loss = 0.16080513\n","Iteration 30, loss = 0.15917885\n","Iteration 31, loss = 0.16100347\n","Iteration 32, loss = 0.15423688\n","Iteration 33, loss = 0.15459494\n","Iteration 34, loss = 0.15132658\n","Iteration 35, loss = 0.15120742\n","Iteration 36, loss = 0.14894235\n","Iteration 37, loss = 0.14707165\n","Iteration 38, loss = 0.14585812\n","Iteration 39, loss = 0.14574699\n","Iteration 40, loss = 0.14391754\n","Iteration 41, loss = 0.14499268\n","Iteration 42, loss = 0.14185310\n","Iteration 43, loss = 0.14145699\n","Iteration 44, loss = 0.14101324\n","Iteration 45, loss = 0.14002517\n","Iteration 46, loss = 0.13855745\n","Iteration 47, loss = 0.13547355\n","Iteration 48, loss = 0.13899055\n","Iteration 49, loss = 0.13766757\n","Iteration 50, loss = 0.13368836\n","Iteration 51, loss = 0.13561097\n","Iteration 52, loss = 0.13314616\n","Iteration 53, loss = 0.13288307\n","Iteration 54, loss = 0.13104453\n","Iteration 55, loss = 0.13146422\n","Iteration 56, loss = 0.12675707\n","Iteration 57, loss = 0.13097460\n","Iteration 58, loss = 0.12699186\n","Iteration 59, loss = 0.12488643\n","Iteration 60, loss = 0.12649362\n","Iteration 61, loss = 0.12447708\n","Iteration 62, loss = 0.12196240\n","Iteration 63, loss = 0.12381088\n","Iteration 64, loss = 0.12301453\n","Iteration 65, loss = 0.12310051\n","Iteration 66, loss = 0.12123960\n","Iteration 67, loss = 0.11771471\n","Iteration 68, loss = 0.12045164\n","Iteration 69, loss = 0.11754698\n","Iteration 70, loss = 0.11442263\n","Iteration 71, loss = 0.11803121\n","Iteration 72, loss = 0.12050981\n","Iteration 73, loss = 0.11145148\n","Iteration 74, loss = 0.11514995\n","Iteration 75, loss = 0.11357025\n","Iteration 76, loss = 0.11089426\n","Iteration 77, loss = 0.11214818\n","Iteration 78, loss = 0.10878057\n","Iteration 79, loss = 0.10771123\n","Iteration 80, loss = 0.10789411\n","Iteration 81, loss = 0.10570714\n","Iteration 82, loss = 0.10647828\n","Iteration 83, loss = 0.10465044\n","Iteration 84, loss = 0.10660707\n","Iteration 85, loss = 0.10377305\n","Iteration 86, loss = 0.10166441\n","Iteration 87, loss = 0.10397156\n","Iteration 88, loss = 0.10169381\n","Iteration 89, loss = 0.10561606\n","Iteration 90, loss = 0.10253084\n","Iteration 91, loss = 0.09745406\n","Iteration 92, loss = 0.09958343\n","Iteration 93, loss = 0.09630254\n","Iteration 94, loss = 0.09743404\n","Iteration 95, loss = 0.09543692\n","Iteration 96, loss = 0.09517786\n","Iteration 97, loss = 0.09514120\n","Iteration 98, loss = 0.09467734\n","Iteration 99, loss = 0.09507570\n","Iteration 100, loss = 0.09323311\n","Iteration 101, loss = 0.09257204\n","Iteration 102, loss = 0.09119566\n","Iteration 103, loss = 0.09238784\n","Iteration 104, loss = 0.08831208\n","Iteration 105, loss = 0.09441179\n","Iteration 106, loss = 0.08751683\n","Iteration 107, loss = 0.09078754\n","Iteration 108, loss = 0.08595727\n","Iteration 109, loss = 0.08506419\n","Iteration 110, loss = 0.08273997\n","Iteration 111, loss = 0.08610706\n","Iteration 112, loss = 0.08685935\n","Iteration 113, loss = 0.08847448\n","Iteration 114, loss = 0.08205688\n","Iteration 115, loss = 0.08467634\n","Iteration 116, loss = 0.08132388\n","Iteration 117, loss = 0.07903707\n","Iteration 118, loss = 0.08515493\n","Iteration 119, loss = 0.08144153\n","Iteration 120, loss = 0.07514025\n","Iteration 121, loss = 0.07897096\n","Iteration 122, loss = 0.07565778\n","Iteration 123, loss = 0.07624435\n","Iteration 124, loss = 0.07369914\n","Iteration 125, loss = 0.07260066\n","Iteration 126, loss = 0.07529892\n","Iteration 127, loss = 0.07307000\n","Iteration 128, loss = 0.07056061\n","Iteration 129, loss = 0.07547446\n","Iteration 130, loss = 0.07648889\n","Iteration 131, loss = 0.07428780\n","Iteration 132, loss = 0.07020428\n","Iteration 133, loss = 0.07812775\n","Iteration 134, loss = 0.07235845\n","Iteration 135, loss = 0.07239908\n","Iteration 136, loss = 0.06905985\n","Iteration 137, loss = 0.06580804\n","Iteration 138, loss = 0.06797148\n","Iteration 139, loss = 0.06739561\n","Iteration 140, loss = 0.06379693\n","Iteration 141, loss = 0.07119336\n","Iteration 142, loss = 0.06557773\n","Iteration 143, loss = 0.06736037\n","Iteration 144, loss = 0.07095657\n","Iteration 145, loss = 0.06489673\n","Iteration 146, loss = 0.06152023\n","Iteration 147, loss = 0.06178228\n","Iteration 148, loss = 0.06610906\n","Iteration 149, loss = 0.06015898\n","Iteration 150, loss = 0.05941728\n","Iteration 151, loss = 0.05885798\n","Iteration 152, loss = 0.06421345\n","Iteration 153, loss = 0.06029278\n","Iteration 154, loss = 0.05992959\n","Iteration 155, loss = 0.06046052\n","Iteration 156, loss = 0.05694593\n","Iteration 157, loss = 0.05557034\n","Iteration 158, loss = 0.05582592\n","Iteration 159, loss = 0.05848000\n","Iteration 160, loss = 0.05780413\n","Iteration 161, loss = 0.05412321\n","Iteration 162, loss = 0.05492229\n","Iteration 163, loss = 0.05728405\n","Iteration 164, loss = 0.05477656\n","Iteration 165, loss = 0.05261470\n","Iteration 166, loss = 0.05136755\n","Iteration 167, loss = 0.05295351\n","Iteration 168, loss = 0.05322684\n","Iteration 169, loss = 0.05422715\n","Iteration 170, loss = 0.05295234\n","Iteration 171, loss = 0.05001747\n","Iteration 172, loss = 0.04995917\n","Iteration 173, loss = 0.04956202\n","Iteration 174, loss = 0.04881592\n","Iteration 175, loss = 0.04889854\n","Iteration 176, loss = 0.05165516\n","Iteration 177, loss = 0.05167967\n","Iteration 178, loss = 0.05023231\n","Iteration 179, loss = 0.04826904\n","Iteration 180, loss = 0.04721380\n","Iteration 181, loss = 0.05007107\n","Iteration 182, loss = 0.04691751\n","Iteration 183, loss = 0.04727002\n","Iteration 184, loss = 0.04582391\n","Iteration 185, loss = 0.04819208\n","Iteration 186, loss = 0.04582501\n","Iteration 187, loss = 0.04993039\n","Iteration 188, loss = 0.04462338\n","Iteration 189, loss = 0.04665248\n","Iteration 190, loss = 0.05101691\n","Iteration 191, loss = 0.04842123\n","Iteration 192, loss = 0.04512880\n","Iteration 193, loss = 0.04404603\n","Iteration 194, loss = 0.03971389\n","Iteration 195, loss = 0.04609994\n","Iteration 196, loss = 0.04305956\n","Iteration 197, loss = 0.04369220\n","Iteration 198, loss = 0.03877573\n","Iteration 199, loss = 0.04053745\n","Iteration 200, loss = 0.03853874\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Wav2Vec2.0 + MLP Test Accuracy: 0.9419\n"]}]},{"cell_type":"code","source":["train_acc = clf.score(X_train_wav2vec, Y_train)\n","test_acc = clf.score(X_test_wav2vec, Y_test)\n","\n","print(f\"✅ Training Accuracy: {train_acc:.4f}\")\n","print(f\"✅ Test Accuracy: {test_acc:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cz1YHa6NxXZW","executionInfo":{"status":"ok","timestamp":1740150036875,"user_tz":-60,"elapsed":9622,"user":{"displayName":"Yijie Xu","userId":"05131023991450583544"}},"outputId":"0e4ab27c-d6b7-41e7-b59e-bdb28a76f640"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["✅ Training Accuracy: 0.9905\n","✅ Test Accuracy: 0.9419\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"GdmRcivp7TF-"},"execution_count":null,"outputs":[]}]}